{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and Importing"
      ],
      "metadata": {
        "id": "NJcw_A8JIsPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.4.0'\n",
        "spark_version = 'spark-3.4.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGTbo8-VGgn3",
        "outputId": "a7cf7bd5-13bb-4c65-c348-5649e60f4b4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Waiting for headers] [3 InRelease 2,588 B/110 kB 2%] [Connected to ppa.laun\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,004 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,343 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,081 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,269 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,038 kB in 3s (1,962 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "metadata": {
        "id": "AiOQ-JiEHA6X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p6jF0DdipcjO"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading CSV and Exploring Data"
      ],
      "metadata": {
        "id": "8_o_mvlhJJ2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import and read the Heart_Disease_Prediction.csv\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://raw.githubusercontent.com/AleidvdZ/Project4HeartDisease/main/Heart_Disease_Prediction.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "hd_df = spark.read.csv(SparkFiles.get(\"Heart_Disease_Prediction.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "hd_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DtO0UoxC3G5",
        "outputId": "91f3eb13-8b83-45be-e54f-3a1507b5e463"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "|index|Age|Sex|Chest pain type| BP|Cholesterol|FBS over 120|EKG results|Max HR|Exercise angina|ST depression|Slope of ST|Number of vessels fluro|Thallium|Heart Disease|\n",
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "|    0| 70|  1|              4|130|        322|           0|          2|   109|              0|          2.4|          2|                      3|       3|     Presence|\n",
            "|    1| 67|  0|              3|115|        564|           0|          2|   160|              0|          1.6|          2|                      0|       7|      Absence|\n",
            "|    2| 57|  1|              2|124|        261|           0|          0|   141|              0|          0.3|          1|                      0|       7|     Presence|\n",
            "|    3| 64|  1|              4|128|        263|           0|          0|   105|              1|          0.2|          2|                      1|       7|      Absence|\n",
            "|    4| 74|  0|              2|120|        269|           0|          2|   121|              1|          0.2|          1|                      1|       3|      Absence|\n",
            "|    5| 65|  1|              4|120|        177|           0|          0|   140|              0|          0.4|          1|                      0|       7|      Absence|\n",
            "|    6| 56|  1|              3|130|        256|           1|          2|   142|              1|          0.6|          2|                      1|       6|     Presence|\n",
            "|    7| 59|  1|              4|110|        239|           0|          2|   142|              1|          1.2|          2|                      1|       7|     Presence|\n",
            "|    8| 60|  1|              4|140|        293|           0|          2|   170|              0|          1.2|          2|                      2|       7|     Presence|\n",
            "|    9| 63|  0|              4|150|        407|           0|          2|   154|              0|          4.0|          2|                      3|       7|     Presence|\n",
            "|   10| 59|  1|              4|135|        234|           0|          0|   161|              0|          0.5|          2|                      0|       7|      Absence|\n",
            "|   11| 53|  1|              4|142|        226|           0|          2|   111|              1|          0.0|          1|                      0|       7|      Absence|\n",
            "|   12| 44|  1|              3|140|        235|           0|          2|   180|              0|          0.0|          1|                      0|       3|      Absence|\n",
            "|   13| 61|  1|              1|134|        234|           0|          0|   145|              0|          2.6|          2|                      2|       3|     Presence|\n",
            "|   14| 57|  0|              4|128|        303|           0|          2|   159|              0|          0.0|          1|                      1|       3|      Absence|\n",
            "|   15| 71|  0|              4|112|        149|           0|          0|   125|              0|          1.6|          2|                      0|       3|      Absence|\n",
            "|   16| 46|  1|              4|140|        311|           0|          0|   120|              1|          1.8|          2|                      2|       7|     Presence|\n",
            "|   17| 53|  1|              4|140|        203|           1|          2|   155|              1|          3.1|          3|                      0|       7|     Presence|\n",
            "|   18| 64|  1|              1|110|        211|           0|          2|   144|              1|          1.8|          2|                      0|       3|      Absence|\n",
            "|   19| 40|  1|              1|140|        199|           0|          0|   178|              1|          1.4|          1|                      0|       7|      Absence|\n",
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show schema\n",
        "hd_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xbov2M3C7ha",
        "outputId": "81426fd9-9af4-429d-ee76-6d1af77a5041"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- index: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Chest pain type: string (nullable = true)\n",
            " |-- BP: string (nullable = true)\n",
            " |-- Cholesterol: string (nullable = true)\n",
            " |-- FBS over 120: string (nullable = true)\n",
            " |-- EKG results: string (nullable = true)\n",
            " |-- Max HR: string (nullable = true)\n",
            " |-- Exercise angina: string (nullable = true)\n",
            " |-- ST depression: string (nullable = true)\n",
            " |-- Slope of ST: string (nullable = true)\n",
            " |-- Number of vessels fluro: string (nullable = true)\n",
            " |-- Thallium: string (nullable = true)\n",
            " |-- Heart Disease: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary view of the DataFrame.\n",
        "hd_df.createOrReplaceTempView('data')\n",
        "\n",
        "# Look at data using SparkSQL\n",
        "spark.sql(\"select * from data limit 10\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTRdiNfFKo93",
        "outputId": "95ca0847-1973-4dfd-b6fb-b4a46187eb93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "|index|Age|Sex|Chest pain type| BP|Cholesterol|FBS over 120|EKG results|Max HR|Exercise angina|ST depression|Slope of ST|Number of vessels fluro|Thallium|Heart Disease|\n",
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "|    0| 70|  1|              4|130|        322|           0|          2|   109|              0|          2.4|          2|                      3|       3|     Presence|\n",
            "|    1| 67|  0|              3|115|        564|           0|          2|   160|              0|          1.6|          2|                      0|       7|      Absence|\n",
            "|    2| 57|  1|              2|124|        261|           0|          0|   141|              0|          0.3|          1|                      0|       7|     Presence|\n",
            "|    3| 64|  1|              4|128|        263|           0|          0|   105|              1|          0.2|          2|                      1|       7|      Absence|\n",
            "|    4| 74|  0|              2|120|        269|           0|          2|   121|              1|          0.2|          1|                      1|       3|      Absence|\n",
            "|    5| 65|  1|              4|120|        177|           0|          0|   140|              0|          0.4|          1|                      0|       7|      Absence|\n",
            "|    6| 56|  1|              3|130|        256|           1|          2|   142|              1|          0.6|          2|                      1|       6|     Presence|\n",
            "|    7| 59|  1|              4|110|        239|           0|          2|   142|              1|          1.2|          2|                      1|       7|     Presence|\n",
            "|    8| 60|  1|              4|140|        293|           0|          2|   170|              0|          1.2|          2|                      2|       7|     Presence|\n",
            "|    9| 63|  0|              4|150|        407|           0|          2|   154|              0|          4.0|          2|                      3|       7|     Presence|\n",
            "+-----+---+---+---------------+---+-----------+------------+-----------+------+---------------+-------------+-----------+-----------------------+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze:\n",
        "\n",
        "*  Total number of indiviuals\n",
        "*  Number/percent of individuals of each sex\n",
        "*  Mean/Median/Mode of ages by sex\n",
        "*  % of male/female with heart disease"
      ],
      "metadata": {
        "id": "z4zzrdzuO2CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total number of indiviuals\n",
        "spark.sql(\"\"\"\n",
        "  SELECT COUNT(index) AS Number_of_Indiv\n",
        "  FROM data\n",
        "    \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSqI4oFEOwYP",
        "outputId": "9df403d0-7742-4551-ea9f-15c568bf48dd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|Number_of_Indiv|\n",
            "+---------------+\n",
            "|            270|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean/Median/Mode of ages (by sex)\n",
        "spark.sql(\"\"\"\n",
        "  SELECT\n",
        "    MIN(Age) AS min_value,\n",
        "    MAX(Age) AS max_value,\n",
        "    ROUND(AVG(Age),1) AS mean_value,\n",
        "    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY Age) AS median_value,\n",
        "    ROUND(STDDEV(Age),1) AS std_deviation,\n",
        "    COUNT(Age) AS count\n",
        "FROM data;\n",
        "    \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JqA_DQtYRwd",
        "outputId": "31da6f89-5e8a-47cc-a98f-c1c1b64f3b1b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------+------------+-------------+-----+\n",
            "|min_value|max_value|mean_value|median_value|std_deviation|count|\n",
            "+---------+---------+----------+------------+-------------+-----+\n",
            "|       29|       77|      54.4|        55.0|          9.1|  270|\n",
            "+---------+---------+----------+------------+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Percent of individuals of each sex (0 = female, 1 = male)\n",
        "spark.sql(\"\"\"\n",
        "  SELECT Sex,\n",
        "  COUNT(*) AS Frequency\n",
        "  FROM data\n",
        "  GROUP BY Sex\n",
        "  ORDER BY Frequency DESC\n",
        "  \"\"\").show()\n",
        "\n",
        "\n",
        "  # SELECT Sex\n",
        "  #   (COUNT(*) / (SELECT COUNT(*) FROM data)) * 100 AS Percentage\n",
        "  #   FROM data\n",
        "  #   GROUP BY Sex\n",
        "  #   ORDER BY Percentage DESC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d_2jDLvTz1y",
        "outputId": "8e0c637f-94a6-48ed-e329-ac5adecc2026"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+\n",
            "|Sex|Frequency|\n",
            "+---+---------+\n",
            "|  1|      183|\n",
            "|  0|       87|\n",
            "+---+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ],
      "metadata": {
        "id": "siSC6JYpa_p9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename columns  \n",
        "Convert Strings to Integers (all columns)  \n",
        "Heart Disease or Not: presence = 1, absence = 0  \n",
        "Scaling: Age, BP, Cholesterol, MaxHR, StDep  \n",
        "Dummy (more than 2 categories): Chest Pain, EKG Result, Slope of ST, Thalium  "
      ],
      "metadata": {
        "id": "TtYCJ89JcnXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q2z8PxtAgKZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Model - Neural Network"
      ],
      "metadata": {
        "id": "ZFYyDHt9aBc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Heart Disease target from features data (NOTE: NEED TO UPDATE COLUMNS)\n",
        "y = hd_df.Heart_Disease.values\n",
        "X = hd_df.drop(columns=\"Heart_Disease\").values\n",
        "\n",
        "# Split training/test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
      ],
      "metadata": {
        "id": "iHwZWqnfaN4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "d1B29HzletRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  8\n",
        "hidden_nodes_layer2 = 3\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "id": "m9qnZTKGe3wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pa-HByTafNWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ],
      "metadata": {
        "id": "HPEVSTXUfUMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "u2cdd7rlfi8M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}